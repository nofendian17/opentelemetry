services:
  # Node Exporter for Linux hosts metrics
  node-exporter:
    image: prom/node-exporter:v1.9.1
    volumes:
      - /proc:/host/proc:ro
      - /sys:/host/sys:ro
      - /:/rootfs:ro
    command:
      - '--path.procfs=/host/proc'
      - '--path.sysfs=/host/sys'
      - '--path.rootfs=/rootfs'
      - '--collector.filesystem.mount-points-exclude=^/(sys|proc|dev|host|etc)($|/)'
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 64M
        reservations:
          memory: 32M

  # Promtail (log shipping)
  promtail:
    image: grafana/promtail:3.5.5
    volumes:
      - ./loki/promtail.yaml:/etc/promtail/promtail.yaml:ro
      - /var/lib/docker/containers:/var/lib/docker/containers:ro
      - /var/log:/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/promtail/promtail.yaml
    depends_on:
      - loki
    restart: unless-stopped
    healthcheck:
      test: [ "CMD-SHELL", "bash -c 'exec 3<>/dev/tcp/127.0.0.1/9080 && printf \"GET /ready HTTP/1.0\\r\\nHost: localhost\\r\\n\\r\\n\" >&3; grep -q Ready <&3'" ]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    deploy:
      resources:
        limits:
          memory: 128M
        reservations:
          memory: 64M

  # OpenTelemetry Collector
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.135.0
    command: [ "--config=/etc/otel-collector-config.yaml" ]
    volumes:
      - ./config/otel-collector-config.yaml:/etc/otel-collector-config.yaml:ro
      - ./config/htpasswd:/etc/otel-collector/htpasswd:ro
    ports:
      - "4318:4318"   # OTLP HTTP receiver (only externally exposed non-Grafana port retained)
      - "4317:4317"   # OTLP gRPC receiver
    environment:
      - OTEL_ENV=development
    restart: unless-stopped
    # The healthcheck was removed because the official otel-collector-contrib image is distroless
    # and does not contain the necessary tools (shell, grep, curl, etc.) to perform the healthcheck.
    # The collector's internal health_check extension is still active and can be seen in the logs.
    depends_on:
      - tempo
      - prometheus
      - loki
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # Tempo for traces
  tempo:
    image: grafana/tempo:2.8.2
    volumes:
      - ./tempo/tempo.yaml:/etc/tempo.yaml:ro
      - tempo_data:/var/tempo
    command: [ "-config.file=/etc/tempo.yaml" ]
    healthcheck:
      test: [ "CMD", "wget", "-qO", "-", "http://localhost:3200/ready" ]
      interval: 30s
      timeout: 5s
      retries: 5
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 512M    # Limit memory to 512MB
        reservations:
          memory: 256M    # Reserve 256MB

  # Prometheus for metrics
  prometheus:
    image: prom/prometheus:v3.5.0
    # External port 9090 removed; reachable internally for Grafana scraping
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--storage.tsdb.path=/prometheus'
      - '--web.console.libraries=/etc/prometheus/console_libraries'
      - '--web.console.templates=/etc/prometheus/consoles'
      - '--storage.tsdb.retention.time=200h'
      - '--web.enable-lifecycle'
      - '--web.enable-remote-write-receiver'
    volumes:
      - ./prometheus/prometheus.yml:/etc/prometheus/prometheus.yml:ro
      - prometheus_data:/prometheus
    healthcheck:
      test: [ "CMD", "wget", "-qO", "-", "http://localhost:9090/-/ready" ]
      interval: 30s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 512M
        reservations:
          memory: 256M

  # Loki for logs
  loki:
    image: grafana/loki:3.5.5
    # External port 3100 removed; Grafana queries Loki internally
    volumes:
      - ./loki/loki-config.yaml:/etc/loki/loki-config.yaml:ro
      - /var/run/docker.sock:/var/run/docker.sock
    command: -config.file=/etc/loki/loki-config.yaml
    healthcheck:
      test: [ "CMD", "wget", "-qO", "-", "http://localhost:3100/ready" ]
      interval: 30s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # Grafana Alloy for telemetry collection
  alloy:
    image: grafana/alloy:latest
    command: ["run", "/etc/alloy/alloy-config.alloy", "--server.http.listen-addr=0.0.0.0:12345"]
    volumes:
      - ./alloy/alloy-config.alloy:/etc/alloy/alloy-config.alloy:ro
      - /var/log:/var/log:ro
      - /var/run/docker.sock:/var/run/docker.sock
      - alloy_data:/var/lib/alloy/data
    depends_on:
      - prometheus
      - loki
      - tempo
      - node-exporter
    environment:
      - ALLOY_CONFIG_FILE=/etc/alloy/alloy-config.alloy
    healthcheck:
      test: ["CMD", "wget", "-qO", "-", "http://localhost:12345/-/ready"]
      interval: 30s
      timeout: 5s
      retries: 5
      start_period: 10s
    restart: unless-stopped
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

  # Grafana for visualization
  grafana:
    image: grafana/grafana:latest
    volumes:
      - ./grafana/provisioning/datasources:/etc/grafana/provisioning/datasources:ro
      - ./grafana/provisioning/dashboards:/etc/grafana/provisioning/dashboards:ro
      - grafana_data:/var/lib/grafana
    ports:
      - "3000:3000"
    depends_on:
      prometheus:
        condition: service_started
      loki:
        condition: service_started
    environment:
      - GF_SECURITY_ADMIN_USER=admin
      - GF_SECURITY_ADMIN_PASSWORD=admin
      - GF_USERS_ALLOW_SIGN_UP=false
    healthcheck:
      test: [ "CMD", "wget", "-qO", "-", "http://localhost:3000/api/health" ]
      interval: 30s
      timeout: 5s
      retries: 5
    deploy:
      resources:
        limits:
          memory: 256M
        reservations:
          memory: 128M

volumes:
  prometheus_data:
  grafana_data:
  tempo_data:
  alloy_data:
